ceph介绍：
ceph统一的、分布式的存储系统，可以提供对象存储、块存储和文件系统存储三种功能。
Based upon RADOS, Ceph Storage Clusters consist of two types of daemons: a Ceph OSD Daemon (OSD) stores data as objects on a storage node; and a Ceph Monitor (MON) maintains a master copy of the cluster map. A Ceph Storage Cluster may contain thousands of storage nodes. A minimal system will have at least one Ceph Monitor and two Ceph OSD Daemons for data replication.
The Ceph Filesystem, Ceph Object Storage and Ceph Block Devices read data from and write data to the Ceph Storage Cluster.
ceph Filesystem clients需要ceph Metadata Server，ceph Block Devices和Ceph Object Storage不用MDS。


根据Ceph官方文档推荐，一个ceph storage cluster需要至少一个ceph monitor和至少两个ceph OSD Daemons来获得avtive-clean的状态.
step1: 利用docker在集群中布置一个ceph monitor和多个ceph OSD Daemons
202作monitor，203作OSD，
参考：Running Ceph inside Docker
在docker hub里有很多的镜像，我们使用Ceph的命名空间，镜像前缀都是ceph/<daemon>
docker run -d --net=host -v /etc/ceph:/etc/ceph -v /var/lib/ceph/:/var/lib/ceph -e MON_IP=10.10.10.202 -e CEPH_PUBLIC_NETWORK=10.10.10.202/24 ceph/daemon mon
然后查看状态
docker ps
docker exec dockerID ceph -s
查看生成的ceph.conf和ceph keyring文件
ls /etc/ceph/
ls /var/lib/ceph/
ls /var/lib/ceph/mon/ceph-zodiac-02
![](http://docs.ceph.com/docs/master/_images/ditaa-cffd08dd3e192a5f1d724ad7930cb04200b9b425.png)
deploy OSD：
docker run -d --net=host --privileged=true -v /etc/ceph:/etc/ceph -v /var/lib/ceph/:/var/lib/ceph -v /dev/:/dev/ -e OSD_DEVICE=/dev/vdd ceph-daemon osd_ceph_disk
this order can't work.QQQ：
docker run -d --net=host -v /etc/ceph:/etc/ceph -v /var/lib/ceph:/var/lib/ceph \
-v /dev:/dev --privileged=true -e OSD_FORCE_ZAP=1 \
-e OSD_DEVICE=/dev/sdb ceph/daemon osd_ceph_disk
启动osd进程
docker exec 7c2ceeb668d3 ceph-osd -i 0/1
查看osd状态
docker exec 7c2ceeb668d3 ceph osd stat

deploy MDS:
docker run -d --net=host -v /etc/ceph:/etc/ceph -v /var/lib/ceph:/var/lib/ceph \
-e CEPHFS_CREATE=1 ceph/daemon mds
查看mds状态
ceph mds stat 
---------
203 deploy node
scp -r core@10.10.10.202:/etc/ceph/ core@10.10.10.204:/etc/
keyring：permission denied。

step2：ceph.conf和Ceph keyring都在step1中启动监测模块时生成，部署多节点，需要把config和keys分发到其他节点。
为了方便，在docker中部署，用etcd存储ceph.conf和ceph keyring等配置文件。
https://github.com/ceph/ceph-docker/tree/master/examples/coreos/units-etcd




add mon,mds
PS：每台主机只能为ceph集群启动一个mon进程
PS2：集群中只有两个mon节点时，其中一个断开会导致集群不能访问，建议mon总数3个或以上。

youtube视频中的步骤
getenforce
./1-selinux
./2-mon
执行玩这两步后就相当与执行了docker run，
#now i need to distribute those config and keys to the 2 other nod
./3-copy
#now I'm going to move the 2 others and apply the config
./3-restore#切换到3上
ls /etc/ceph















